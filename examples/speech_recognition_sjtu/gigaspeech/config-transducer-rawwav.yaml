# @package _group_ 


common:
  log_interval: 100
  log_format: json
  tensorboard_logdir: tb
  # wandb_project: fairseq-gigaspeech-transducer-debug
  profile: false
  seed: 1
  fp16: true

distributed_training:
  distributed_world_size: 1
  ddp_backend: pytorch_ddp

dataset:
  num_workers: 4
  max_tokens: 1000000
  skip_invalid_size_inputs_valid_test: true
  train_subset: train-s-100h
  valid_subset: dev-tidy
  validate_interval: 1
  validate_interval_updates: 0
  max_tokens_valid: 1000000

optimization:
  max_update: 90000
  clip_norm: 5.0
  sentence_avg: false
  # update_freq: [8]
  update_freq: [5]
  lr: [0.0005]

optimizer:
  _name: adam
  adam_betas: (0.9,0.999)
  adam_eps: 1.0e-08
  weight_decay: 0.01

lr_scheduler:
  # _name: inverse_sqrt
  _name: linear_decay
  warmup_updates: 10000

model:
    _name: sr_transducer
    encoder_type: data2vec
    # encoder_type: transformer
    ssl_model_path: /home/chenxie95/github/fairseq/outputs/ssl_models/audio_base_ls.pt
    encoder_embed_dim: 768
    encoder_ffn_embed_dim: 2048
    encoder_attention_heads: 8
    encoder_layers: 12
    # encoder output subsampling
    use_encoder_output_subsampler: false
    pool_kernel_size: 6
    pool_stride_size: 6
    pool_padding_size: 0
    # decoder config
    decoder_embed_dim: 768
    decoder_ffn_embed_dim: 2048
    decoder_layers: 6
    decoder_output_dim: 768
    decoder_attention_heads: 8
    decoder_hidden_size: 768 
    decoder_num_layers: 2
    decoder_dropout_in: 0.1
    decoder_dropout_out: 0.1
    joint_dim: 768

criterion:
  _name: transducer_loss
  sentence_avg: true
  use_local_rnnt_loss: true

checkpoint:
  save_dir: /home/chenxie95/github/fairseq/outputs/asr_gigaspeech_transducer_rawwav_noinit
  save_interval_updates: 0
  keep_interval_updates: -1
  no_epoch_checkpoints: false

task:
  _name: speech_recognition
  data: /mnt/data/GigaSpeech/gigaspeech-s-rawwav
  config_yaml: config.yaml
  max_source_positions: 320000

hydra:
    run:
        dir: ${checkpoint.save_dir}
