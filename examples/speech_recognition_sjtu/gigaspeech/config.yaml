# @package _group_ 


common:
  log_interval: 100
  log_format: json
  tensorboard_logdir: tb
  wandb_project: fairseq-gigaspeech
  seed: 1
  fp16: true

distributed_training:
  distributed_world_size: 1
  ddp_backend: pytorch_ddp

dataset:
  num_workers: 4
  max_tokens: 40000
  skip_invalid_size_inputs_valid_test: true
  train_subset: train-m
  valid_subset: dev-tidy
  validate_interval: 1
  validate_interval_updates: 0
  max_tokens_valid: 40000

optimization:
  max_update: 60000
  clip_norm: 5.0
  sentence_avg: false
  update_freq: [8]
  lr: [0.0005]

optimizer:
  _name: adam
  adam_betas: (0.9,0.999)
  adam_eps: 1.0e-08
  weight_decay: 0.01

lr_scheduler:
  _name: inverse_sqrt
  warmup_updates: 10000

model:
  _name: sr_transformer
  share_decoder_input_output_embed: true
  encoder_embed_dim: 512
  encoder_ffn_embed_dim: 2048
  encoder_layers: 16
  decoder_embed_dim: 512
  decoder_ffn_embed_dim: 2048
  decoder_layers: 6
  decoder_output_dim: 512
  encoder_attention_heads: 8
  decoder_attention_heads: 8


criterion:
  _name: label_smoothed_cross_entropy
  label_smoothing: 0.1
  report_accuracy: true
  ignore_prefix_size: 0
  sentence_avg: false

checkpoint:
  save_dir: /home/chenxie95/github/fairseq/outputs/asr_gigaspeech.lr0.0005
  save_interval_updates: 0
  keep_interval_updates: -1
  no_epoch_checkpoints: false

task:
  _name: speech_recognition
  data: /mnt/data/GigaSpeech/tempdir
  config_yaml: config.yaml

hydra:
    run:
        dir: ${checkpoint.save_dir}
